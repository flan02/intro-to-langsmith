{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using filters in the SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `list_runs` method in the SDK or `/runs/query` endpoint in the API, you can filter runs to analyze and export."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's paste in the raw query we copied from the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_query = \"\"\"eq(name, \"call_openai\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=UUID('45c10bde-df31-4ba1-8271-ec136097cf3a') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 22, 42, 47, 621806) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 22, 42, 49, 980155) extra={'metadata': {'ls_method': 'traceable', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'revision_id': '456547e-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nWhenever possible, provide a python code example to help the user get started!\\n\", 'role': 'system'}, {'content': \"Context: 2. Log a trace\\u200b\\nOnce you've set up your environment, you can call LangChain runnables as normal.\\nLangSmith will infer the proper tracing config:\\n\\nHow to log and view traces to LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n2. Log a trace\\u200b\\nOnce you've set up your environment, wrap or decorate the custom functions/SDKs you want to trace.\\nLangSmith will then infer the proper tracing config:\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityTutorialsAdd observability to your LLM applicationHow-to GuidesTracingAnnotate code for tracingToggle tracing on and offUpload files with tracesLog traces to specific projectSet a sampling rate for tracesAdd metadata and tags to tracesImplement distributed tracingAccess the current run (span) within a traced functionLog multimodal tracesLog retriever tracesLog custom LLM tracesPrevent logging of sensitive data in tracesQuery tracesShare or unshare a trace publiclyCompare tracesTrace generator functionsTrace with LangChain (Python and JS/TS)Trace with LangGraph (Python and JS/TS)Trace with Instructor (Python only)Trace with OpenTelemetryTrace with the Vercel AI SDK (JS/TS only)Trace without setting environment variablesTrace using the LangSmith REST APICalculate token-based costs for tracesTroubleshoot trace nesting[Beta] Bulk Exporting Trace DataHow to print detailed logs (Python SDK)Trace JS functions in serverless environmentsMonitoring and automationsConceptual GuideEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceObservabilityHow-to GuidesTracingAnnotate code for tracingOn this pageAnnotate code for tracing\\nThere are several ways to log traces to LangSmith.\\ntipIf you are using LangChain (either Python or JS/TS), you can skip this section and go directly to the LangChain-specific instructions.\\nUse @traceable / traceable\\u200b\\nLangSmith makes it easy to log traces with minimal changes to your existing code with the @traceable decorator in Python and traceable function in TypeScript.\\n\\n Question: How do I set up tracing to LangSmith with @traceable?\", 'role': 'user'}]} outputs={'output': {'id': 'chatcmpl-AmTcW7GkQAvk6XA41iZa66ZMA5cff', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': \"To set up tracing to LangSmith using the `@traceable` decorator in Python, simply import the decorator and apply it to the functions you want to trace. Here's an example:\\n\\n```python\\nfrom langsmith import traceable\\n\\n@traceable\\ndef my_function():\\n    # Your function code here\\n    pass\\n```\\n\\nThis will enable tracing for `my_function` with minimal changes to your existing code.\", 'role': 'assistant'}}], 'created': 1736116968, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_d02d531b47', 'usage': {'completion_tokens': 85, 'prompt_tokens': 559, 'total_tokens': 644, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('a631441a-1e89-4de6-8d55-7b753eb7d659') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/45c10bde-df31-4ba1-8271-ec136097cf3a?trace_id=87814bcc-7487-4bee-b751-17691df57082&start_time=2025-01-05T22:42:46.676431' manifest_id=None status='success' prompt_tokens=559 completion_tokens=85 total_tokens=644 first_token_time=None total_cost=Decimal('0.00013485') prompt_cost=Decimal('0.00008385') completion_cost=Decimal('0.000051') parent_run_ids=[UUID('87814bcc-7487-4bee-b751-17691df57082'), UUID('a631441a-1e89-4de6-8d55-7b753eb7d659')] trace_id=UUID('87814bcc-7487-4bee-b751-17691df57082') dotted_order='20250105T224246676431Z87814bcc-7487-4bee-b751-17691df57082.20250105T224247116806Za631441a-1e89-4de6-8d55-7b753eb7d659.20250105T224247621806Z45c10bde-df31-4ba1-8271-ec136097cf3a' in_dataset=False\n",
      "id=UUID('b721b016-143b-48ae-a9b5-6d768c7630aa') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 22, 14, 40, 364355) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 22, 14, 41, 905060) extra={'metadata': {'ls_method': 'traceable', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'revision_id': '456547e-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': \"Context: 2. Log a trace\\u200b\\nOnce you've set up your environment, you can call LangChain runnables as normal.\\nLangSmith will infer the proper tracing config:\\n\\nHow to log and view traces to LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n2. Log a trace\\u200b\\nOnce you've set up your environment, wrap or decorate the custom functions/SDKs you want to trace.\\nLangSmith will then infer the proper tracing config:\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityTutorialsAdd observability to your LLM applicationHow-to GuidesTracingAnnotate code for tracingToggle tracing on and offUpload files with tracesLog traces to specific projectSet a sampling rate for tracesAdd metadata and tags to tracesImplement distributed tracingAccess the current run (span) within a traced functionLog multimodal tracesLog retriever tracesLog custom LLM tracesPrevent logging of sensitive data in tracesQuery tracesShare or unshare a trace publiclyCompare tracesTrace generator functionsTrace with LangChain (Python and JS/TS)Trace with LangGraph (Python and JS/TS)Trace with Instructor (Python only)Trace with OpenTelemetryTrace with the Vercel AI SDK (JS/TS only)Trace without setting environment variablesTrace using the LangSmith REST APICalculate token-based costs for tracesTroubleshoot trace nesting[Beta] Bulk Exporting Trace DataHow to print detailed logs (Python SDK)Trace JS functions in serverless environmentsMonitoring and automationsConceptual GuideEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceObservabilityHow-to GuidesTracingAnnotate code for tracingOn this pageAnnotate code for tracing\\nThere are several ways to log traces to LangSmith.\\ntipIf you are using LangChain (either Python or JS/TS), you can skip this section and go directly to the LangChain-specific instructions.\\nUse @traceable / traceable\\u200b\\nLangSmith makes it easy to log traces with minimal changes to your existing code with the @traceable decorator in Python and traceable function in TypeScript. \\n\\n Question: How do I set up tracing to LangSmith with @traceable?\"}]} outputs={'output': {'id': 'chatcmpl-AmTBJK3APZSOpYbY8vFr8tvFmE6IQ', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'To set up tracing to LangSmith using the @traceable decorator in Python, simply wrap or decorate the custom functions or SDKs you want to trace with @traceable. After that, LangSmith will automatically infer the appropriate tracing configuration. This allows you to log traces with minimal changes to your existing code.', 'role': 'assistant'}}], 'created': 1736115281, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 63, 'prompt_tokens': 545, 'total_tokens': 608, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('5df04378-b147-4655-9e2d-d0891185e425') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/b721b016-143b-48ae-a9b5-6d768c7630aa?trace_id=ee0cb2cc-ec99-4e02-80ec-248e66f43665&start_time=2025-01-05T22:14:39.700146' manifest_id=None status='success' prompt_tokens=545 completion_tokens=63 total_tokens=608 first_token_time=None total_cost=Decimal('0.00011955') prompt_cost=Decimal('0.00008175') completion_cost=Decimal('0.0000378') parent_run_ids=[UUID('ee0cb2cc-ec99-4e02-80ec-248e66f43665'), UUID('5df04378-b147-4655-9e2d-d0891185e425')] trace_id=UUID('ee0cb2cc-ec99-4e02-80ec-248e66f43665') dotted_order='20250105T221439700146Zee0cb2cc-ec99-4e02-80ec-248e66f43665.20250105T221440364355Z5df04378-b147-4655-9e2d-d0891185e425.20250105T221440364355Zb721b016-143b-48ae-a9b5-6d768c7630aa' in_dataset=False\n",
      "id=UUID('57e6f01c-2b22-44a7-82dc-b8d8299fc66f') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 22, 13, 58, 998483) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 22, 14, 0, 844031) extra={'metadata': {'ls_method': 'traceable', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'revision_id': '456547e-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': \"Context: 2. Log a trace\\u200b\\nOnce you've set up your environment, you can call LangChain runnables as normal.\\nLangSmith will infer the proper tracing config:\\n\\nHow to log and view traces to LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n2. Log a trace\\u200b\\nOnce you've set up your environment, wrap or decorate the custom functions/SDKs you want to trace.\\nLangSmith will then infer the proper tracing config:\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityTutorialsAdd observability to your LLM applicationHow-to GuidesTracingAnnotate code for tracingToggle tracing on and offUpload files with tracesLog traces to specific projectSet a sampling rate for tracesAdd metadata and tags to tracesImplement distributed tracingAccess the current run (span) within a traced functionLog multimodal tracesLog retriever tracesLog custom LLM tracesPrevent logging of sensitive data in tracesQuery tracesShare or unshare a trace publiclyCompare tracesTrace generator functionsTrace with LangChain (Python and JS/TS)Trace with LangGraph (Python and JS/TS)Trace with Instructor (Python only)Trace with OpenTelemetryTrace with the Vercel AI SDK (JS/TS only)Trace without setting environment variablesTrace using the LangSmith REST APICalculate token-based costs for tracesTroubleshoot trace nesting[Beta] Bulk Exporting Trace DataHow to print detailed logs (Python SDK)Trace JS functions in serverless environmentsMonitoring and automationsConceptual GuideEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceObservabilityHow-to GuidesTracingAnnotate code for tracingOn this pageAnnotate code for tracing\\nThere are several ways to log traces to LangSmith.\\ntipIf you are using LangChain (either Python or JS/TS), you can skip this section and go directly to the LangChain-specific instructions.\\nUse @traceable / traceable\\u200b\\nLangSmith makes it easy to log traces with minimal changes to your existing code with the @traceable decorator in Python and traceable function in TypeScript. \\n\\n Question: How do I set up tracing to LangSmith with @traceable?\"}]} outputs={'output': {'id': 'chatcmpl-AmTAetOmB8elWs2QA8ygPJrVAAYoq', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'To set up tracing to LangSmith with the @traceable decorator in Python, simply wrap or decorate the custom functions or SDKs you wish to trace. LangSmith will then infer the proper tracing configuration automatically. Make sure your environment is set up before this step to ensure proper functionality.', 'role': 'assistant'}}], 'created': 1736115240, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 57, 'prompt_tokens': 545, 'total_tokens': 602, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('60d9f0c2-93ab-4f18-ad81-ed33b4913d9d') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/57e6f01c-2b22-44a7-82dc-b8d8299fc66f?trace_id=ff1f0f9d-6df7-494f-a5c3-3e32111ab997&start_time=2025-01-05T22:13:58.056367' manifest_id=None status='success' prompt_tokens=545 completion_tokens=57 total_tokens=602 first_token_time=None total_cost=Decimal('0.00011595') prompt_cost=Decimal('0.00008175') completion_cost=Decimal('0.0000342') parent_run_ids=[UUID('ff1f0f9d-6df7-494f-a5c3-3e32111ab997'), UUID('60d9f0c2-93ab-4f18-ad81-ed33b4913d9d')] trace_id=UUID('ff1f0f9d-6df7-494f-a5c3-3e32111ab997') dotted_order='20250105T221358056367Zff1f0f9d-6df7-494f-a5c3-3e32111ab997.20250105T221358997482Z60d9f0c2-93ab-4f18-ad81-ed33b4913d9d.20250105T221358998483Z57e6f01c-2b22-44a7-82dc-b8d8299fc66f' in_dataset=False\n",
      "id=UUID('72157224-74bf-4b5d-96ae-75d69a4f73d1') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 13, 51, 5, 69490) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 13, 51, 8, 117377) extra={'metadata': {'ls_method': 'traceable', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'revision_id': '456547e-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': \"Context: 2. Log a trace\\u200b\\nOnce you've set up your environment, you can call LangChain runnables as normal.\\nLangSmith will infer the proper tracing config:\\n\\nHow to log and view traces to LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\nLangSmith + LangChain OSSLangSmith integrates seamlessly with LangChain's open source frameworks langchain and langgraph, with no extra instrumentation needed.If you're already using either of these, see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\\nLangSmith is a standalone platform that can be used on it's own no matter how you're creating your LLM applicatons.\\nIn this tutorial, we'll walk you though logging your first trace in LangSmith using the LangSmith SDK and running an evaluation to measure the performance of your application. This example uses the OpenAI API, however you can use your provider of choice.\\n1. Install LangSmith\\u200b\\nPythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\\n2. Create an API key\\u200b\\nTo create an API key head to the Settings page. Then click Create API Key.\\n3. Set up your environment\\u200b\\nShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key>export OPENAI_API_KEY=<your-openai-api-key>\\n4. Log your first trace\\u200b\\nWe provide multiple ways to log traces to LangSmith. Below, we'll highlight\\nhow to use traceable(). See more on the Annotate code for tracing page.\\n\\nnoteThe LANGCHAIN_TRACING_V2 environment variable must be set to 'true' in order for traces to be logged to LangSmith, even when using wrap_openai or wrapOpenAI. This allows you to toggle tracing on and off without changing your code.Additionally, you will need to set the LANGCHAIN_API_KEY environment variable to your API key (see Setup for more information).By default, the traces will be logged to a project named default.\\nTo log traces to a different project, see this section. \\n\\n Question: How do I set up tracing to LangSmith if I'm using LangChain?\"}]} outputs={'output': {'id': 'chatcmpl-AmLJxEQLHzpA2h6HjNKQ5ZgIrsDTC', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'To set up tracing to LangSmith while using LangChain, first install LangSmith and OpenAI with the command `pip install -U langsmith openai`. Then, create an API key via the Settings page and set up your environment by exporting `LANGCHAIN_TRACING_V2=true`, `LANGCHAIN_API_KEY=<your-api-key>`, and `OPENAI_API_KEY=<your-openai-api-key>`. Finally, ensure that traces are logged by using traceable() and confirming the LANGCHAIN_TRACING_V2 environment variable is set.', 'role': 'assistant'}}], 'created': 1736085065, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_d02d531b47', 'usage': {'completion_tokens': 110, 'prompt_tokens': 503, 'total_tokens': 613, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('ae043835-afd3-4807-b2f3-f2676f915d2a') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/72157224-74bf-4b5d-96ae-75d69a4f73d1?trace_id=0fca5918-e8b5-4126-b905-5f331cce73ce&start_time=2025-01-05T13:51:03.973194' manifest_id=None status='success' prompt_tokens=503 completion_tokens=110 total_tokens=613 first_token_time=None total_cost=Decimal('0.00014145') prompt_cost=Decimal('0.00007545') completion_cost=Decimal('0.000066') parent_run_ids=[UUID('0fca5918-e8b5-4126-b905-5f331cce73ce'), UUID('ae043835-afd3-4807-b2f3-f2676f915d2a')] trace_id=UUID('0fca5918-e8b5-4126-b905-5f331cce73ce') dotted_order='20250105T135103973194Z0fca5918-e8b5-4126-b905-5f331cce73ce.20250105T135105069490Zae043835-afd3-4807-b2f3-f2676f915d2a.20250105T135105069490Z72157224-74bf-4b5d-96ae-75d69a4f73d1' in_dataset=False\n",
      "id=UUID('1d43dfb8-1e0c-416b-b777-a87563dabcf6') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 13, 20, 40, 781700) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 13, 20, 42, 148157) extra={'metadata': {'thread_id': '53fa08dd-54f9-4d0e-acbb-cb9b73dc2dad', 'ls_method': 'traceable', 'revision_id': '456547e-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the latest question in the conversation. \\n    If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise.\\n    \"}, {'role': 'user', 'content': \"Context: Adding metadata and tags to traces\\x00\\x00\\u200b\\nLangSmith supports sending arbitrary metadata and tags along with traces. This is useful for associating additional information with a trace, such as the environment in which it was executed, or the user who initiated it.\\nFor more information on metadata and tags, see the Concepts page. For information on how to query traces and runs by metadata and tags, see the Querying Traces page.\\n\\nAdd metadata and tags to traces | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\nLangSmith allows you to manually annotate traces with feedback within the application. This can be useful for adding context to a trace, such as a user's comment or a note about a specific issue.\\nYou can annotate a trace either inline or by sending the trace to an annotation queue, which allows you closely inspect and log feedbacks to runs one at a time.\\nFeedback tags are associated with your workspace.\\nnoteYou can attach user feedback to ANY intermediate run (span) of the trace, not just the root span.\\nThis is useful for critiquing specific parts of the LLM application, such as the retrieval step or generation step of the RAG pipeline.\\nTo annotate a trace inline, click on the Annotate in the upper right corner of trace view for any particular run that is part of the trace.\\n\\nOr you can send the trace to the Annotation Queue\\n\\nYou can annotate the trace in an Annotation Queue using one of the feedback tags associated with your tenant (or create a new one)\\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousQuerying TracesNextQuerying FeedbackCapturing feedback programmaticallyAnnotating traces with feedbackCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc. \\n\\n Question: How can I add tags to a Trace?\"}], 'model': 'gpt-4o-mini', 'temperature': 0.0} outputs={'output': {'id': 'chatcmpl-AmKqX5yFa8JbtGg3Y8vN0FGNDSgFL', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'You can add tags to a trace in LangSmith by sending arbitrary metadata and tags along with the trace. Additionally, you can annotate a trace inline or send it to an annotation queue, where you can use feedback tags associated with your workspace. For more detailed instructions, refer to the Concepts page or the Querying Traces page.', 'role': 'assistant'}}], 'created': 1736083241, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 67, 'prompt_tokens': 452, 'total_tokens': 519, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('9e20d4e4-1e07-4e42-905c-38d6faf3aa2e') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/1d43dfb8-1e0c-416b-b777-a87563dabcf6?trace_id=36b36991-48fe-4997-9a20-7ae2af5c118d&start_time=2025-01-05T13:20:39.881075' manifest_id=None status='success' prompt_tokens=452 completion_tokens=67 total_tokens=519 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('36b36991-48fe-4997-9a20-7ae2af5c118d'), UUID('9e20d4e4-1e07-4e42-905c-38d6faf3aa2e')] trace_id=UUID('36b36991-48fe-4997-9a20-7ae2af5c118d') dotted_order='20250105T132039881075Z36b36991-48fe-4997-9a20-7ae2af5c118d.20250105T132040781700Z9e20d4e4-1e07-4e42-905c-38d6faf3aa2e.20250105T132040781700Z1d43dfb8-1e0c-416b-b777-a87563dabcf6' in_dataset=False\n",
      "id=UUID('c702d238-9ea1-49c3-94fa-6544f0b35446') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 13, 20, 37, 196948) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 13, 20, 38, 919149) extra={'metadata': {'thread_id': '53fa08dd-54f9-4d0e-acbb-cb9b73dc2dad', 'ls_method': 'traceable', 'revision_id': '456547e-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the latest question in the conversation. \\n    If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise.\\n    \"}, {'role': 'user', 'content': 'Context: Adding metadata and tags to traces\\x00\\x00\\u200b\\nLangSmith supports sending arbitrary metadata and tags along with traces. This is useful for associating additional information with a trace, such as the environment in which it was executed, or the user who initiated it.\\nFor more information on metadata and tags, see the Concepts page. For information on how to query traces and runs by metadata and tags, see the Querying Traces page.\\n\\nAdd metadata and tags to traces | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\nYou can then click into a particular thread. This will open the history for a particular thread. If your threads are formatted as chat messages, you will a chatbot-like UI where you can see a history of inputs and outputs.\\n\\nWhat are special metadata keys that associate traces as part of the same thread?\\u200b\\nIn order to log runs as part of the same thread you need to pass a special metadata key to the run. The key value is the unique identifier for that conversation.\\nThe key name should be one of:\\n\\nsession_id\\nthread_id\\nconversation_id.\\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousMonitoringNextOnline EvaluationHow to view threadsWhat are special metadata keys that associate traces as part of the same thread?CommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.\\n\\nYou can track threads by attaching a special metadata key to runs (one of session_id, thread_id or conversation_id).\\nSee this documentation for how to add metadata keys to a trace.\\nMonitoring Dashboard\\u200b\\nMonitoring dashboards display key metrics over time for a configurable time window. We track LLM related statistics like latency, feedback, time-to-first-token, cost, and more. You can see these dashboard by going to the Monitors tab.\\nRules\\u200b\\nRules represent actions that are taken on a set of runs. These are configured by a specifying a filter rule, a sampling rate, and an action to take. Currently, the supported actions are adding to dataset, adding to annotation queue, and sending to online evaluation.\\nAn example of a rule could be, in plain English, \"Run a \\'vagueness\\' evaluator on 70% of root runs with a feedback score of 0 for the feedback key user_score\"\\nDatasets\\u200b\\nDatasets are a way to collect examples, which are input-output pairs. You can use datasets for evaluation, as well as fine-tuning and few-shot prompting. For more information, see here\\nAnnotation Queues\\u200b\\nAnnotation Queues are a user-friendly way to annotate a lot of traces.\\nOnline Evaluation\\u200b\\nOnline evaluation is when an LLM is used to assign feedback to particular runs.Was this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextHow-To GuidesRunsTracesFilterThreadsMonitoring DashboardRulesDatasetsAnnotation QueuesOnline EvaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc. \\n\\n Question: How do I add metadata to a Trace?'}], 'model': 'gpt-4o-mini', 'temperature': 0.0} outputs={'output': {'id': 'chatcmpl-AmKqTgHDTG1WFZHZTXn4N4QrKOtyh', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'To add metadata to a trace in LangSmith, you need to send arbitrary metadata and tags along with the trace. This can include information like the execution environment or the user who initiated the trace. For detailed instructions, refer to the documentation on adding metadata keys to a trace.', 'role': 'assistant'}}], 'created': 1736083237, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 56, 'prompt_tokens': 710, 'total_tokens': 766, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('7175781c-e89f-4943-a302-794e9f0029bc') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/c702d238-9ea1-49c3-94fa-6544f0b35446?trace_id=daad57ab-dcd5-4f37-8e1d-bbe24c3cbeb3&start_time=2025-01-05T13:20:36.224882' manifest_id=None status='success' prompt_tokens=710 completion_tokens=56 total_tokens=766 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('daad57ab-dcd5-4f37-8e1d-bbe24c3cbeb3'), UUID('7175781c-e89f-4943-a302-794e9f0029bc')] trace_id=UUID('daad57ab-dcd5-4f37-8e1d-bbe24c3cbeb3') dotted_order='20250105T132036224882Zdaad57ab-dcd5-4f37-8e1d-bbe24c3cbeb3.20250105T132037196948Z7175781c-e89f-4943-a302-794e9f0029bc.20250105T132037196948Zc702d238-9ea1-49c3-94fa-6544f0b35446' in_dataset=False\n",
      "id=UUID('f2f2e1c1-85fa-44f6-99ab-c33c3058ac91') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 12, 52, 25, 207687) run_type='chain' end_time=datetime.datetime(2025, 1, 5, 12, 52, 28, 20804) extra={'metadata': {'ls_method': 'traceable', 'revision_id': '456547e'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': 'Context: Notice how we import from langsmith.wrappers import wrap_openai and use it to wrap the OpenAI client (openai_client = wrap_openai(OpenAI())).\\nWhat happens if you call it in the following way?\\nrag(\"where did harrison work\")\\nThis will produce a trace of just the OpenAI call - it should look something like this\\n\\nnoteThe LANGCHAIN_TRACING_V2 environment variable must be set to \\'true\\' in order for traces to be logged to LangSmith, even when using wrap_openai or wrapOpenAI. This allows you to toggle tracing on and off without changing your code.Additionally, you will need to set the LANGCHAIN_API_KEY environment variable to your API key (see Setup for more information).By default, the traces will be logged to a project named default.\\nTo log traces to a different project, see this section.\\n\\nnoteThe LANGCHAIN_TRACING_V2 environment variable must be set to \\'true\\' in order for traces to be logged to LangSmith, even when using wrap_openai or wrapOpenAI. This allows you to toggle tracing on and off without changing your code.Additionally, you will need to set the LANGCHAIN_API_KEY environment variable to your API key (see Setup for more information).By default, the traces will be logged to a project named default.\\nTo log traces to a different project, see this section.\\n\\nThis will produce a trace of just the entire pipeline (with the OpenAI call as a child run) - it should look something like this \\n\\n Question: How do I trace with wrap_openai?'}]} outputs={'output': {'id': 'chatcmpl-AmKPBx9ZyevXZlxmYqIhgpGQRwDdh', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': \"To trace with `wrap_openai`, set the `LANGCHAIN_TRACING_V2` environment variable to 'true' and ensure the `LANGCHAIN_API_KEY` environment variable is configured with your API key. When these conditions are met, calling the function will produce a trace of the OpenAI call or the entire pipeline, depending on the tracing setup. By default, traces are logged to a project named 'default', but you can configure it to log to a different project if needed.\", 'role': 'assistant'}}], 'created': 1736081545, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_d02d531b47', 'usage': {'completion_tokens': 99, 'prompt_tokens': 387, 'total_tokens': 486, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('ed6c3bdc-a76f-4c99-860b-a14547e1d8e4') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/f2f2e1c1-85fa-44f6-99ab-c33c3058ac91?trace_id=85c065b6-9bff-487f-8fff-b2a7ab1e3ccd&start_time=2025-01-05T12:52:24.389749' manifest_id=None status='success' prompt_tokens=0 completion_tokens=0 total_tokens=0 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('85c065b6-9bff-487f-8fff-b2a7ab1e3ccd'), UUID('ed6c3bdc-a76f-4c99-860b-a14547e1d8e4')] trace_id=UUID('85c065b6-9bff-487f-8fff-b2a7ab1e3ccd') dotted_order='20250105T125224389749Z85c065b6-9bff-487f-8fff-b2a7ab1e3ccd.20250105T125225207687Zed6c3bdc-a76f-4c99-860b-a14547e1d8e4.20250105T125225207687Zf2f2e1c1-85fa-44f6-99ab-c33c3058ac91' in_dataset=False\n",
      "id=UUID('3ff32a57-2635-4f4b-8d96-79e8c6a1d291') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 12, 46, 19, 766402) run_type='chain' end_time=datetime.datetime(2025, 1, 5, 12, 46, 21, 699717) extra={'metadata': {'ls_method': 'traceable', 'revision_id': '456547e'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': 'Context: An example trace from running the above code looks like this:\\n\\nView a sample output trace.\\nLearn more about tracing on the tracing page.\\n\\nUse the trace context manager (Python only)\\u200b\\nIn Python, you can use the trace context manager to log traces to LangSmith. This is useful in situations where:\\n\\nYou want to log traces for a specific block of code.\\nYou want control over the inputs, outputs, and other attributes of the trace.\\nIt is not feasible to use a decorator or wrapper.\\nAny or all of the above.\\n\\nThe above code will log the following trace: \\n\\n Question: How do I trace with tracing context?'}], 'model': 'gpt-4o-mini', 'temperature': 0.0} outputs={'output': {'id': 'chatcmpl-AmKJIWCK7saOto2ThYXRDSWRZRUfY', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'To trace with the tracing context manager in Python, you can use it to log traces for a specific block of code. This allows you to control the inputs, outputs, and other attributes of the trace, especially when using a decorator or wrapper is not feasible. Simply wrap the desired code block with the trace context manager to log the trace.', 'role': 'assistant'}}], 'created': 1736081180, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 69, 'prompt_tokens': 193, 'total_tokens': 262, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('2ea8a5f5-17fd-4f91-b6f1-7b5e8fe6a310') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/3ff32a57-2635-4f4b-8d96-79e8c6a1d291?trace_id=2ea8a5f5-17fd-4f91-b6f1-7b5e8fe6a310&start_time=2025-01-05T12:46:18.932457' manifest_id=None status='success' prompt_tokens=0 completion_tokens=0 total_tokens=0 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('2ea8a5f5-17fd-4f91-b6f1-7b5e8fe6a310')] trace_id=UUID('2ea8a5f5-17fd-4f91-b6f1-7b5e8fe6a310') dotted_order='20250105T124618932457Z2ea8a5f5-17fd-4f91-b6f1-7b5e8fe6a310.20250105T124619766402Z3ff32a57-2635-4f4b-8d96-79e8c6a1d291' in_dataset=False\n",
      "id=UUID('82797c0c-d352-4a48-8b44-3137e52a919c') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 12, 35, 55, 168215) run_type='chain' end_time=datetime.datetime(2025, 1, 5, 12, 35, 57, 660815) extra={'metadata': {'ls_method': 'traceable', 'revision_id': '456547e'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': 'Context: An example trace from running the above code looks like this:\\n\\nView a sample output trace.\\nLearn more about tracing on the tracing page.\\n\\nUse the trace context manager (Python only)\\u200b\\nIn Python, you can use the trace context manager to log traces to LangSmith. This is useful in situations where:\\n\\nYou want to log traces for a specific block of code.\\nYou want control over the inputs, outputs, and other attributes of the trace.\\nIt is not feasible to use a decorator or wrapper.\\nAny or all of the above.\\n\\nThe above code will log the following trace: \\n\\n Question: How do I trace with tracing context?'}], 'model': 'gpt-4o-mini', 'temperature': 0.0} outputs={'output': {'id': 'chatcmpl-AmK9DqQTqOuUkWxG6gsPCiCQkHswM', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'To trace with the tracing context in Python, you can use the trace context manager to log traces for a specific block of code. This allows you to control the inputs, outputs, and other attributes of the trace. It is particularly useful when using a decorator or wrapper is not feasible.', 'role': 'assistant'}}], 'created': 1736080555, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 58, 'prompt_tokens': 193, 'total_tokens': 251, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('3f5f7d80-c5ed-4b5e-bf36-a72dc0ba7a04') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/82797c0c-d352-4a48-8b44-3137e52a919c?trace_id=f980616e-339a-4988-aa0f-039c2ccab9bf&start_time=2025-01-05T12:35:54.495203' manifest_id=None status='success' prompt_tokens=0 completion_tokens=0 total_tokens=0 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('f980616e-339a-4988-aa0f-039c2ccab9bf'), UUID('3f5f7d80-c5ed-4b5e-bf36-a72dc0ba7a04')] trace_id=UUID('f980616e-339a-4988-aa0f-039c2ccab9bf') dotted_order='20250105T123554495203Zf980616e-339a-4988-aa0f-039c2ccab9bf.20250105T123555168215Z3f5f7d80-c5ed-4b5e-bf36-a72dc0ba7a04.20250105T123555168215Z82797c0c-d352-4a48-8b44-3137e52a919c' in_dataset=False\n",
      "id=UUID('52ba9a2a-9bb5-4e70-8266-f234d8ca19f0') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 3, 51, 12, 14757) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 3, 51, 12, 602680) extra={'metadata': {'ls_method': 'traceable', 'revision_id': 'e72232b-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'What is the weather today in New York City?'}, {'role': 'assistant', 'tool_calls': [{'id': 'call_Myw7iP0bKBDzG1abnSsk6XLi', 'function': {'arguments': '{\"location\":\"New York City, NY\",\"unit\":\"Fahrenheit\"}', 'name': 'get_current_temperature'}, 'type': 'function'}]}, {'role': 'tool', 'content': '{\"location\": \"New York City, NY\", \"unit\": \"Fahrenheit\", \"temperature\": 65}', 'tool_call_id': 'call_Myw7iP0bKBDzG1abnSsk6XLi'}], 'tools': None} outputs={'output': {'id': 'chatcmpl-AmBxQbISC7bzEdChDim7s4mO2DSVr', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'The current temperature in New York City is 65¬∞F. If you need more detailed weather information, feel free to ask!', 'role': 'assistant'}}], 'created': 1736049072, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_d02d531b47', 'usage': {'completion_tokens': 26, 'prompt_tokens': 83, 'total_tokens': 109, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/52ba9a2a-9bb5-4e70-8266-f234d8ca19f0?trace_id=1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5&start_time=2025-01-05T03:51:10.820544' manifest_id=None status='success' prompt_tokens=83 completion_tokens=26 total_tokens=109 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5')] trace_id=UUID('1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5') dotted_order='20250105T035110820544Z1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5.20250105T035112014757Z52ba9a2a-9bb5-4e70-8266-f234d8ca19f0' in_dataset=False\n",
      "id=UUID('67a02f87-58ff-4d67-a664-daf8d744707b') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 3, 51, 10, 820544) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 3, 51, 12, 13758) extra={'metadata': {'ls_method': 'traceable', 'revision_id': 'e72232b-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'What is the weather today in New York City?'}], 'tools': [{'type': 'function', 'function': {'name': 'get_current_temperature', 'description': 'Get the current temperature for a specific location', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g., San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['Celsius', 'Fahrenheit'], 'description': \"The temperature unit to use. Infer this from the user's location.\"}}, 'required': ['location', 'unit']}}}]} outputs={'output': {'id': 'chatcmpl-AmBxPRKxCrMCn2TmGmXedaP2fVRLO', 'choices': [{'finish_reason': 'tool_calls', 'index': 0, 'message': {'role': 'assistant', 'tool_calls': [{'id': 'call_Myw7iP0bKBDzG1abnSsk6XLi', 'function': {'arguments': '{\"location\":\"New York City, NY\",\"unit\":\"Fahrenheit\"}', 'name': 'get_current_temperature'}, 'type': 'function'}]}}], 'created': 1736049071, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_d02d531b47', 'usage': {'completion_tokens': 25, 'prompt_tokens': 101, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/67a02f87-58ff-4d67-a664-daf8d744707b?trace_id=1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5&start_time=2025-01-05T03:51:10.820544' manifest_id=None status='success' prompt_tokens=101 completion_tokens=25 total_tokens=126 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5')] trace_id=UUID('1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5') dotted_order='20250105T035110820544Z1cebbbf9-b5f4-4699-b86e-5f5c2475e5b5.20250105T035110820544Z67a02f87-58ff-4d67-a664-daf8d744707b' in_dataset=False\n",
      "id=UUID('9bf4586b-ff1b-4bf4-9007-7ebaba9028e7') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 3, 50, 49, 904619) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 3, 50, 50, 573556) extra={'metadata': {'ls_method': 'traceable', 'revision_id': 'e72232b-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'What is the weather today in New York City?'}, {'role': 'assistant', 'tool_calls': [{'id': 'call_fiQXUjLcywFDsHa1RmF55h6r', 'function': {'arguments': '{\"location\":\"New York City, NY\",\"unit\":\"Fahrenheit\"}', 'name': 'get_current_temperature'}, 'type': 'function'}]}, {'role': 'tool', 'content': '{\"location\": \"New York City, NY\", \"unit\": \"Fahrenheit\", \"temperature\": 65}', 'tool_call_id': 'call_fiQXUjLcywFDsHa1RmF55h6r'}], 'tools': None} outputs={'output': {'id': 'chatcmpl-AmBx4hR4Ygmoy3q5cWRxyF6qZKJzZ', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'The current temperature in New York City is 65¬∞F. If you need more specific weather details, such as conditions or forecasts, let me know!', 'role': 'assistant'}}], 'created': 1736049050, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_d02d531b47', 'usage': {'completion_tokens': 31, 'prompt_tokens': 83, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('bad8e228-a200-497c-938c-8a64d1321ce9') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/9bf4586b-ff1b-4bf4-9007-7ebaba9028e7?trace_id=bad8e228-a200-497c-938c-8a64d1321ce9&start_time=2025-01-05T03:50:48.727749' manifest_id=None status='success' prompt_tokens=83 completion_tokens=31 total_tokens=114 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('bad8e228-a200-497c-938c-8a64d1321ce9')] trace_id=UUID('bad8e228-a200-497c-938c-8a64d1321ce9') dotted_order='20250105T035048727749Zbad8e228-a200-497c-938c-8a64d1321ce9.20250105T035049904619Z9bf4586b-ff1b-4bf4-9007-7ebaba9028e7' in_dataset=False\n",
      "id=UUID('7da3447e-42e8-4ce8-99f2-db128370183b') name='call_openai' start_time=datetime.datetime(2025, 1, 5, 3, 50, 48, 727749) run_type='llm' end_time=datetime.datetime(2025, 1, 5, 3, 50, 49, 831617) extra={'metadata': {'ls_method': 'traceable', 'revision_id': 'e72232b-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'What is the weather today in New York City?'}], 'tools': [{'type': 'function', 'function': {'name': 'get_current_temperature', 'description': 'Get the current temperature for a specific location', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g., San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['Celsius', 'Fahrenheit'], 'description': \"The temperature unit to use. Infer this from the user's location.\"}}, 'required': ['location', 'unit']}}}]} outputs={'output': {'id': 'chatcmpl-AmBx32FPo6vT3oBreU7t4zDxJxqKA', 'choices': [{'finish_reason': 'tool_calls', 'index': 0, 'message': {'role': 'assistant', 'tool_calls': [{'id': 'call_fiQXUjLcywFDsHa1RmF55h6r', 'function': {'arguments': '{\"location\":\"New York City, NY\",\"unit\":\"Fahrenheit\"}', 'name': 'get_current_temperature'}, 'type': 'function'}]}}], 'created': 1736049049, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_d02d531b47', 'usage': {'completion_tokens': 25, 'prompt_tokens': 101, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('bad8e228-a200-497c-938c-8a64d1321ce9') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/7da3447e-42e8-4ce8-99f2-db128370183b?trace_id=bad8e228-a200-497c-938c-8a64d1321ce9&start_time=2025-01-05T03:50:48.727749' manifest_id=None status='success' prompt_tokens=101 completion_tokens=25 total_tokens=126 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('bad8e228-a200-497c-938c-8a64d1321ce9')] trace_id=UUID('bad8e228-a200-497c-938c-8a64d1321ce9') dotted_order='20250105T035048727749Zbad8e228-a200-497c-938c-8a64d1321ce9.20250105T035048727749Z7da3447e-42e8-4ce8-99f2-db128370183b' in_dataset=False\n",
      "id=UUID('de96435d-8e25-4b10-89cb-54ace30ed5d3') name='call_openai' start_time=datetime.datetime(2025, 1, 4, 23, 22, 24, 339970) run_type='chain' end_time=datetime.datetime(2025, 1, 4, 23, 22, 26, 303612) extra={'metadata': {'runtime_metadata': 'foo', 'ls_method': 'traceable', 'model_name': 'gpt-4o-mini', 'model_provider': 'openai', 'revision_id': 'e72232b-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': 'Context: Edit example metadata\\u200b\\nYou can add metadata to your examples by clicking on an example and then clicking on the \"Metadata\" tab in the side pane.\\nFrom this page, you can update/delete existing metadata, or add new metadata. You may use this to store information about\\nyour examples, such as tags or version info, which you can then filter by when you call list_examples in the SDK.\\n\\nFilter examples\\u200b\\nYou can filter examples by metadata key/value or full-text search. To filter examples, click \"Filter\" in the top left of the table:\\n\\nNext, click \"Add filter\" and select \"Full Text\" or \"Metadata\" from the resulting dropdown. You may add multiple filters, and only examples that satisfy all of the\\nfilters will be displayed in the table.\\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousHow to run an evaluationNextHow to bind an evaluator to a dataset in the UISet up your datasetOption 1: Create from CSVOption 2: Create empty DatasetAdd runs to your dataset in the UIAdd runs from the tracing project UIAutomatically add runs to a datasetAdd runs from an annotation queueAdd runs directly via the Datasets UIAdd synthetic examples created by an LLM via the Datasets UIExport a datasetCreate and manage dataset splitsEdit example metadataFilter examplesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.\\n\\nLogging Metadata\\u200b\\nIt is also a good idea to start logging metadata.\\nThis allows you to start keep track of different attributes of your app.\\nThis is important in allowing you to know what version or variant of your app was used to produce a given result.\\nFor this example, we will log the LLM used.\\nOftentimes you may be experimenting with different LLMs, so having that information as metadata can be useful for filtering.\\nIn order to do that, we can add it as such:\\nfrom openai import OpenAIfrom langsmith import traceablefrom langsmith.wrappers import wrap_openaiopenai_client = wrap_openai(OpenAI())@traceable(run_type=\"retriever\")def retriever(query: str):    results = [\"Harrison worked at Kensho\"]    return results@traceable(metadata={\"llm\": \"gpt-4o-mini\"})def rag(question):    docs = retriever(question)    system_message = \"\"\"Answer the users question using only the provided information below:    {docs}\"\"\".format(docs=\\'\\\\n\\'.join(docs))    return openai_client.chat.completions.create(messages = [        {\"role\": \"system\", \"content\": system_message},        {\"role\": \"user\", \"content\": question},    ], model=\"gpt-4o-mini\")\\nNotice we added @traceable(metadata={\"llm\": \"gpt-4o-mini\"}) to the rag function.\\nKeeping track of metadata in this way assumes that it is known ahead of time.\\nThis is fine for LLM types, but less desirable for other types of information - like a User ID.\\nIn order to log information that, we can pass it in at run time with the run ID.\\nimport uuidrun_id = str(uuid.uuid4())rag(    \"where did harrison work\",    langsmith_extra={\"run_id\": run_id, \"metadata\": {\"user_id\": \"harrison\"}})\\n\\nAdding metadata and tags to traces\\x00\\x00\\u200b\\nLangSmith supports sending arbitrary metadata and tags along with traces. This is useful for associating additional information with a trace, such as the environment in which it was executed, or the user who initiated it.\\nFor more information on metadata and tags, see the Concepts page. For information on how to query traces and runs by metadata and tags, see the Querying Traces page.\\n\\nNow that we\\'ve logged these two pieces of metadata, we should be able to see them both show up in the UI here. \\n\\n Question: How do I add metadata at runtime?'}], 'model': 'gpt-4o-mini', 'temperature': 0.0} outputs={'output': {'id': 'chatcmpl-Am7lIomHzxHTpcvQy86JLOuW6vQMz', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'You can add metadata at runtime by passing it in with the run ID using the `langsmith_extra` parameter. For example, you can call your function like this: `rag(\"your question\", langsmith_extra={\"run_id\": run_id, \"metadata\": {\"user_id\": \"harrison\"}})`. This allows you to log information such as a User ID dynamically during execution.', 'role': 'assistant'}}], 'created': 1736032944, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 79, 'prompt_tokens': 887, 'total_tokens': 966, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('3b7fb5a7-c73a-44dd-8e88-5e7c8b2f5344') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/de96435d-8e25-4b10-89cb-54ace30ed5d3?trace_id=3e299612-6f88-4d28-9561-b2c6c3b46058&start_time=2025-01-04T23:22:23.595818' manifest_id=None status='success' prompt_tokens=0 completion_tokens=0 total_tokens=0 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('3e299612-6f88-4d28-9561-b2c6c3b46058'), UUID('3b7fb5a7-c73a-44dd-8e88-5e7c8b2f5344')] trace_id=UUID('3e299612-6f88-4d28-9561-b2c6c3b46058') dotted_order='20250104T232223595818Z3e299612-6f88-4d28-9561-b2c6c3b46058.20250104T232224338970Z3b7fb5a7-c73a-44dd-8e88-5e7c8b2f5344.20250104T232224339970Zde96435d-8e25-4b10-89cb-54ace30ed5d3' in_dataset=False\n",
      "id=UUID('de37263a-d376-48a9-990b-069fd48971db') name='call_openai' start_time=datetime.datetime(2025, 1, 4, 23, 22, 3, 650695) run_type='chain' end_time=datetime.datetime(2025, 1, 4, 23, 22, 5, 170788) extra={'metadata': {'ls_method': 'traceable', 'model_name': 'gpt-4o-mini', 'model_provider': 'openai', 'revision_id': 'e72232b-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': 'Context: Adding metadata and tags to traces\\x00\\x00\\u200b\\nLangSmith supports sending arbitrary metadata and tags along with traces. This is useful for associating additional information with a trace, such as the environment in which it was executed, or the user who initiated it.\\nFor more information on metadata and tags, see the Concepts page. For information on how to query traces and runs by metadata and tags, see the Querying Traces page.\\n\\nThis works for the traceable decorator and RunTree objects.Was this page helpful?You can leave detailed feedback on GitHub.PreviousLog traces to specific projectNextAdd metadata and tags to tracesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.\\n\\nAdd metadata and tags to traces | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\nYou can track threads by attaching a special metadata key to runs (one of session_id, thread_id or conversation_id).\\nSee this documentation for how to add metadata keys to a trace.\\nMonitoring Dashboard\\u200b\\nMonitoring dashboards display key metrics over time for a configurable time window. We track LLM related statistics like latency, feedback, time-to-first-token, cost, and more. You can see these dashboard by going to the Monitors tab.\\nRules\\u200b\\nRules represent actions that are taken on a set of runs. These are configured by a specifying a filter rule, a sampling rate, and an action to take. Currently, the supported actions are adding to dataset, adding to annotation queue, and sending to online evaluation.\\nAn example of a rule could be, in plain English, \"Run a \\'vagueness\\' evaluator on 70% of root runs with a feedback score of 0 for the feedback key user_score\"\\nDatasets\\u200b\\nDatasets are a way to collect examples, which are input-output pairs. You can use datasets for evaluation, as well as fine-tuning and few-shot prompting. For more information, see here\\nAnnotation Queues\\u200b\\nAnnotation Queues are a user-friendly way to annotate a lot of traces.\\nOnline Evaluation\\u200b\\nOnline evaluation is when an LLM is used to assign feedback to particular runs.Was this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextHow-To GuidesRunsTracesFilterThreadsMonitoring DashboardRulesDatasetsAnnotation QueuesOnline EvaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc. \\n\\n Question: How do I add Metadata to a Run with @traceable?'}], 'model': 'gpt-4o-mini', 'temperature': 0.0} outputs={'output': {'id': 'chatcmpl-Am7kxB1gwxS1rJQpJ2QKar1QIcuY7', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'To add metadata to a Run using the @traceable decorator, you can attach a special metadata key to the trace, such as session_id, thread_id, or conversation_id. For detailed instructions on how to implement this, refer to the documentation on adding metadata keys to a trace.', 'role': 'assistant'}}], 'created': 1736032923, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_d02d531b47', 'usage': {'completion_tokens': 58, 'prompt_tokens': 599, 'total_tokens': 657, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('55ebaf5f-5e2c-439b-baa7-75a78c39fec4') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/de37263a-d376-48a9-990b-069fd48971db?trace_id=015262bd-aafe-49dd-966b-56cf12b45af3&start_time=2025-01-04T23:22:02.901669' manifest_id=None status='success' prompt_tokens=0 completion_tokens=0 total_tokens=0 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('015262bd-aafe-49dd-966b-56cf12b45af3'), UUID('55ebaf5f-5e2c-439b-baa7-75a78c39fec4')] trace_id=UUID('015262bd-aafe-49dd-966b-56cf12b45af3') dotted_order='20250104T232202901669Z015262bd-aafe-49dd-966b-56cf12b45af3.20250104T232203650695Z55ebaf5f-5e2c-439b-baa7-75a78c39fec4.20250104T232203650695Zde37263a-d376-48a9-990b-069fd48971db' in_dataset=False\n",
      "id=UUID('0854b3a8-aedf-40b5-a04e-6ff871fad768') name='call_openai' start_time=datetime.datetime(2025, 1, 4, 23, 15, 53, 651377) run_type='chain' end_time=datetime.datetime(2025, 1, 4, 23, 15, 55, 680144) extra={'metadata': {'ls_method': 'traceable', 'revision_id': 'e72232b-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': 'Context: noteThe LANGCHAIN_TRACING_V2 environment variable must be set to \\'true\\' in order for traces to be logged to LangSmith, even when using @traceable or traceable. This allows you to toggle tracing on and off without changing your code.Additionally, you will need to set the LANGCHAIN_API_KEY environment variable to your API key (see Setup for more information).By default, the traces will be logged to a project named default.\\nTo log traces to a different project, see this section.\\nPythonTypeScriptThe @traceable decorator is a simple way to log traces from the LangSmith Python SDK. Simply decorate any function with @traceable.\\nfrom langsmith import traceablefrom openai import Clientopenai = Client()@traceabledef format_prompt(subject):  return [      {          \"role\": \"system\",          \"content\": \"You are a helpful assistant.\",      },      {          \"role\": \"user\",          \"content\": f\"What\\'s a good name for a store that sells {subject}?\"      }  ]@traceable(run_type=\"llm\")def invoke_llm(messages):  return openai.chat.completions.create(      messages=messages, model=\"gpt-4o-mini\", temperature=0  )@traceabledef parse_output(response):  return response.choices[0].message.content@traceabledef run_pipeline():  messages = format_prompt(\"colorful socks\")  response = invoke_llm(messages)  return parse_output(response)run_pipeline()The traceable function is a simple way to log traces from the LangSmith TypeScript SDK. Simply wrap any function with traceable.\\nNote that when wrapping a sync function with traceable, (e.g. formatPrompt in the example below), you should use the await keyword when calling it to ensure the trace is logged correctly.\\n\\nNotice how we import from langsmith import traceable and use it decorate the overall function (@traceable(run_type=\"retriever\")).\\nWhat happens if you call it in the following way?\\nrag(\"where did harrison work\")\\nThis will produce a trace of the whole chain including the retrieval step - it should look something like this\\n\\nAn example trace from running the above code looks like this:\\n\\nExample usage\\u200b\\nYou can extend the utilities above to conveniently trace any code. Below are some example extensions:\\nTrace any public method in a class: \\n\\n Question: How can I trace with the @traceable decorator?'}], 'model': 'gpt-4o-mini', 'temperature': 0.0} outputs={'output': {'id': 'chatcmpl-Am7f06gjE1Q1Q7nFdhBsdA5eE71m6', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': \"To trace with the @traceable decorator, simply decorate any function you want to log traces for by adding `@traceable` above its definition. Ensure that the LANGCHAIN_TRACING_V2 environment variable is set to 'true' and that you have the necessary API key configured. This setup allows you to log traces effectively without modifying your code further.\", 'role': 'assistant'}}], 'created': 1736032554, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 72, 'prompt_tokens': 565, 'total_tokens': 637, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('b5cd963c-53fd-4056-bc1c-8f6937189f7a') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/0854b3a8-aedf-40b5-a04e-6ff871fad768?trace_id=cd211da6-c2e3-499c-88fc-611b9b8ba59f&start_time=2025-01-04T23:15:52.762774' manifest_id=None status='success' prompt_tokens=0 completion_tokens=0 total_tokens=0 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('cd211da6-c2e3-499c-88fc-611b9b8ba59f'), UUID('b5cd963c-53fd-4056-bc1c-8f6937189f7a')] trace_id=UUID('cd211da6-c2e3-499c-88fc-611b9b8ba59f') dotted_order='20250104T231552762774Zcd211da6-c2e3-499c-88fc-611b9b8ba59f.20250104T231553651377Zb5cd963c-53fd-4056-bc1c-8f6937189f7a.20250104T231553651377Z0854b3a8-aedf-40b5-a04e-6ff871fad768' in_dataset=False\n",
      "id=UUID('99a2900b-62bd-4e45-a539-40e5403b0236') name='call_openai' start_time=datetime.datetime(2025, 1, 4, 23, 14, 15, 885401) run_type='chain' end_time=datetime.datetime(2025, 1, 4, 23, 14, 17, 381756) extra={'metadata': {'ls_method': 'traceable', 'revision_id': 'e72232b-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': 'Context: noteThe LANGCHAIN_TRACING_V2 environment variable must be set to \\'true\\' in order for traces to be logged to LangSmith, even when using @traceable or traceable. This allows you to toggle tracing on and off without changing your code.Additionally, you will need to set the LANGCHAIN_API_KEY environment variable to your API key (see Setup for more information).By default, the traces will be logged to a project named default.\\nTo log traces to a different project, see this section.\\nPythonTypeScriptThe @traceable decorator is a simple way to log traces from the LangSmith Python SDK. Simply decorate any function with @traceable.\\nfrom langsmith import traceablefrom openai import Clientopenai = Client()@traceabledef format_prompt(subject):  return [      {          \"role\": \"system\",          \"content\": \"You are a helpful assistant.\",      },      {          \"role\": \"user\",          \"content\": f\"What\\'s a good name for a store that sells {subject}?\"      }  ]@traceable(run_type=\"llm\")def invoke_llm(messages):  return openai.chat.completions.create(      messages=messages, model=\"gpt-4o-mini\", temperature=0  )@traceabledef parse_output(response):  return response.choices[0].message.content@traceabledef run_pipeline():  messages = format_prompt(\"colorful socks\")  response = invoke_llm(messages)  return parse_output(response)run_pipeline()The traceable function is a simple way to log traces from the LangSmith TypeScript SDK. Simply wrap any function with traceable.\\nNote that when wrapping a sync function with traceable, (e.g. formatPrompt in the example below), you should use the await keyword when calling it to ensure the trace is logged correctly.\\n\\nNotice how we import from langsmith import traceable and use it decorate the overall function (@traceable(run_type=\"retriever\")).\\nWhat happens if you call it in the following way?\\nrag(\"where did harrison work\")\\nThis will produce a trace of the whole chain including the retrieval step - it should look something like this\\n\\nAn example trace from running the above code looks like this:\\n\\nExample usage\\u200b\\nYou can extend the utilities above to conveniently trace any code. Below are some example extensions:\\nTrace any public method in a class: \\n\\n Question: How can I trace with the @traceable decorator?'}], 'model': 'gpt-4o-mini', 'temperature': 0.0} outputs={'output': {'id': 'chatcmpl-Am7dQb0Bis65lNkInorGgF8hhtrMM', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': \"To trace with the @traceable decorator, simply decorate any function you want to log traces for by adding `@traceable` above its definition. Ensure that the LANGCHAIN_TRACING_V2 environment variable is set to 'true' and that you have the necessary API key configured. When you run the decorated function, it will automatically log traces to LangSmith.\", 'role': 'assistant'}}], 'created': 1736032456, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 74, 'prompt_tokens': 565, 'total_tokens': 639, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('d4f7be72-a559-4c25-b4ca-959a62cbd330') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/99a2900b-62bd-4e45-a539-40e5403b0236?trace_id=34c30f01-1b39-4eb7-8f7a-018e54a91f80&start_time=2025-01-04T23:14:14.562848' manifest_id=None status='success' prompt_tokens=0 completion_tokens=0 total_tokens=0 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('34c30f01-1b39-4eb7-8f7a-018e54a91f80'), UUID('d4f7be72-a559-4c25-b4ca-959a62cbd330')] trace_id=UUID('34c30f01-1b39-4eb7-8f7a-018e54a91f80') dotted_order='20250104T231414562848Z34c30f01-1b39-4eb7-8f7a-018e54a91f80.20250104T231415885401Zd4f7be72-a559-4c25-b4ca-959a62cbd330.20250104T231415885401Z99a2900b-62bd-4e45-a539-40e5403b0236' in_dataset=False\n",
      "id=UUID('cbfcaa3f-05e1-4284-9a44-e5fca7e1dcca') name='call_openai' start_time=datetime.datetime(2025, 1, 4, 22, 31, 48, 815445) run_type='llm' end_time=datetime.datetime(2025, 1, 4, 22, 31, 50, 585870) extra={'metadata': {'website': 'www.google.com', 'ls_method': 'traceable', 'revision_id': 'e72232b-dirty'}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.2.10', 'library': 'langsmith', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.12.6', 'langchain_version': '0.3.14', 'langchain_core_version': '0.3.29'}} error=None serialized=None events=[] inputs={'messages': [{'role': 'system', 'content': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\"}, {'role': 'user', 'content': \"Context: LangSmith User Guide | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingThis is outdated documentation for ü¶úÔ∏èüõ†Ô∏è LangSmith, which is no longer actively maintained.For up-to-date documentation, see the latest version.User GuideOn this pageLangSmith User Guide\\nLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.\\n\\nPrototyping\\u200b\\nPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing ‚Äî and debug where it is failing ‚Äî is incredibly important for this phase.\\nDebugging\\u200b\\nWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn‚Äôt necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it‚Äôs extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.\\n\\nGet started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceQuick StartOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications.\\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\nWith LangSmith you can:\\n\\nTrace LLM Applications: Gain visibility into LLM calls and other parts of your application's logic.\\nEvaluate Performance: Compare results across models, prompts, and architectures to identify what works best.\\nImprove Prompts: Quickly refine prompts to achieve more accurate and reliable results.\\n\\nGetting started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\nInitial Test Set\\u200b\\nWhile many developers still ship an initial version of their application based on ‚Äúvibe checks‚Äù, we‚Äôve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.\\n\\n\\nComparison View\\u200b\\nWhen prototyping different versions of your applications and making changes, it‚Äôs important to see whether or not you‚Äôve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it‚Äôs useful to be able to view results for different configurations on the same datapoints side-by-side. We‚Äôve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.\\n\\n\\nPlayground\\u200b\\nLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\\nEvery playground run is logged in the system and can be used to create test cases or compare with other runs. \\n\\n Question: What is LangSmith used for?\"}], 'model': 'gpt-4o-mini', 'temperature': 0.0} outputs={'output': {'id': 'chatcmpl-Am6yK0MijR3nQ88WJJXrEtC0ZFrc8', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'LangSmith is a platform for developing, monitoring, and testing large language model (LLM) applications. It supports workflows throughout the application development lifecycle, including prototyping, debugging, and performance evaluation. Users can trace LLM applications, evaluate performance across different models and prompts, and refine prompts for better results.', 'role': 'assistant'}}], 'created': 1736029908, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'system_fingerprint': 'fp_0aa8d3e20b', 'usage': {'completion_tokens': 62, 'prompt_tokens': 940, 'total_tokens': 1002, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}} reference_example_id=None parent_run_id=UUID('882dd5f4-da0c-4f63-b4be-d4933459ebf2') tags=[] attachments={} session_id=UUID('9d03cc7a-7895-4fda-a116-c00e7c812024') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/036832fd-8ebc-5afd-896b-d2f686653c0c/projects/p/9d03cc7a-7895-4fda-a116-c00e7c812024/r/cbfcaa3f-05e1-4284-9a44-e5fca7e1dcca?trace_id=e463056b-0875-4ed8-af3b-d9c17d7e914f&start_time=2025-01-04T22:31:48.075656' manifest_id=None status='success' prompt_tokens=940 completion_tokens=62 total_tokens=1002 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[UUID('e463056b-0875-4ed8-af3b-d9c17d7e914f'), UUID('882dd5f4-da0c-4f63-b4be-d4933459ebf2')] trace_id=UUID('e463056b-0875-4ed8-af3b-d9c17d7e914f') dotted_order='20250104T223148075656Ze463056b-0875-4ed8-af3b-d9c17d7e914f.20250104T223148815445Z882dd5f4-da0c-4f63-b4be-d4933459ebf2.20250104T223148815445Zcbfcaa3f-05e1-4284-9a44-e5fca7e1dcca' in_dataset=False\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "client = Client()\n",
    "runs = client.list_runs(\n",
    "  project_name=\"langsmith-academy\", \n",
    "  filter=raw_query,\n",
    "  start_time=datetime.now() - timedelta(days=1),\n",
    ")\n",
    "for run in runs:\n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in trace or tree filters too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_runs(\n",
    "  project_name=\"langsmith-academy\", \n",
    "  filter=\"eq(is_root, true)\",\n",
    "  # trace_filter=\"\"\n",
    "  # tree_filter=\"\"\n",
    ")\n",
    "for run in runs:\n",
    "    print(run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
